<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Int√©rprete de Libras</title>
  <link rel="stylesheet" href="txtlibras.css">
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 min-h-screen">
  <div class="flex h-screen">
    <!-- Left Panel -->
    <div class="w-1/2 bg-white p-12 flex flex-col border-r border-gray-200">
      <div class="mb-8">
        <h1 class="text-3xl font-bold text-gray-900 mb-2">Int√©rprete de Libras</h1>
        <p class="text-gray-600">Fale no microfone e veja a tradu√ß√£o em tempo real</p>
      </div>

      <!-- Avatar Card -->
      <div class="flex-1 flex items-center justify-center">
        <!-- Added ID and recording state styling -->
        <div id="avatarCard" class="bg-gray-50 rounded-3xl w-full max-w-4xl transition-colors duration-300">
          <div class="flex flex-col items-center">
            <!-- Simple Person Illustration -->
            <!-- Added IDs for animation control -->
            <!-- Replaced SVG avatar with a video element. Uses the project video at ../video-libras/oi.mp4 -->
            <video id="avatarVideo" class="avatar-video" playsinline muted preload="metadata" style="object-fit:cover;">
              <source src="../imagens/IncluIA√™.mp4" type="video/mp4">
              Seu navegador n√£o suporta o elemento de v√≠deo.
            </video>

            <!-- Added ID for status text updates -->
            <p id="statusText" class="text-gray-500 text-center">Aguardando fala...</p>
          </div>
        </div>
      </div>

      <!-- Control Buttons -->
      <div class="flex gap-4 justify-center mt-8">
        <!-- Added IDs and click handlers -->
        <button id="micButton" class="w-16 h-16 rounded-full bg-blue-600 text-white flex items-center justify-center hover:bg-blue-700 transition-colors shadow-lg relative">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
          </svg>
        </button>
        <button id="speakerButton" class="w-16 h-16 rounded-full bg-white border-2 border-gray-200 text-gray-700 flex items-center justify-center hover:bg-gray-50 transition-colors">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
          </svg>
        </button>
      </div>
    </div>

    <!-- Right Panel -->
    <div class="w-1/2 bg-gray-50 p-12 flex flex-col">
      <div class="mb-8">
        <h2 class="text-2xl font-bold text-gray-900 mb-1">Transcri√ß√£o</h2>
        <p class="text-sm text-gray-600">Hist√≥rico de conversas capturadas</p>
      </div>

      <!-- Transcription Area -->
      <!-- Added ID and scrollable container for transcriptions -->
      <div id="transcriptionArea" class="flex-1 overflow-y-auto">
        <div id="welcomeMessage" class="flex items-center justify-center h-full">
          <div class="text-center max-w-md">
            <div class="text-6xl mb-6">üëã</div>
            <h3 class="text-xl font-semibold text-gray-900 mb-4">Bem-vindo ao Int√©rprete de Libras</h3>
            <p class="text-gray-600 leading-relaxed">
              Clique no bot√£o do microfone para come√ßar a falar. Suas palavras ser√£o transcritas e traduzidas para libras em tempo real.
            </p>
          </div>
        </div>
        <!-- Container for transcription entries -->
        <div id="transcriptionList" class="space-y-4 hidden"></div>
      </div>
    </div>
  </div>

  <!-- Added JavaScript functionality -->
  <script>
    // State management
    let isRecording = false;
    let recognition = null;
    let transcriptions = [];

    // DOM elements
    const micButton = document.getElementById('micButton');
    const speakerButton = document.getElementById('speakerButton');
    const statusText = document.getElementById('statusText');
    const avatarCard = document.getElementById('avatarCard');
    const avatarVideo = document.getElementById('avatarVideo');
    const leftArm = document.getElementById('leftArm');
    const rightArm = document.getElementById('rightArm');
    const welcomeMessage = document.getElementById('welcomeMessage');
    const transcriptionList = document.getElementById('transcriptionList');

    // Try to play avatar video up to 2 times per user action (guards for autoplay policies)
    let _avatarPlayCount = 0;
    let _avatarEndedHandler = null;

    function playAvatarVideo() {
      if (!avatarVideo) return;
      try {
        // Ensure video is not in loop mode; we'll control replay manually
        avatarVideo.loop = false;

        // Remove any previous ended handler to avoid duplicates
        if (_avatarEndedHandler) {
          avatarVideo.removeEventListener('ended', _avatarEndedHandler);
          _avatarEndedHandler = null;
        }

        // Reset count and start from beginning
        _avatarPlayCount = 0;
        avatarVideo.currentTime = 0;

        // Handler increments count and replays until we reached 2 plays
        _avatarEndedHandler = function () {
          _avatarPlayCount += 1;
          if (_avatarPlayCount < 2) {
            // play again
            const p = avatarVideo.play();
            if (p && p.catch) p.catch(err => console.warn('[v0] avatar video replay failed:', err));
          } else {
            // finished the second play ‚Äî clean up
            avatarVideo.removeEventListener('ended', _avatarEndedHandler);
            _avatarEndedHandler = null;
            _avatarPlayCount = 0;
          }
        };

        avatarVideo.addEventListener('ended', _avatarEndedHandler);

        const p = avatarVideo.play();
        if (p && p.catch) p.catch(err => console.warn('[v0] avatar video play failed:', err));
      } catch (err) {
        console.warn('[v0] playAvatarVideo error:', err);
      }
    }

    // Initialize Speech Recognition
    function initSpeechRecognition() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      
      if (!SpeechRecognition) {
        alert('Seu navegador n√£o suporta reconhecimento de voz. Por favor, use Chrome ou Edge.');
        return null;
      }

      const recognition = new SpeechRecognition();
      recognition.lang = 'pt-BR';
      recognition.continuous = true;
      recognition.interimResults = true;

      recognition.onstart = () => {
        console.log('[v0] Speech recognition started');
        statusText.textContent = 'Escutando...';
        avatarCard.classList.add('bg-blue-50');
        if (leftArm) leftArm.classList.add('animate-wave');
  // no avatar video playback here; play only when user presses the listen button
      };

      recognition.onresult = (event) => {
        let interimTranscript = '';
        let finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript + ' ';
          } else {
            interimTranscript += transcript;
          }
        }

        if (finalTranscript) {
            console.log('[v0] Final transcript:', finalTranscript);
            addTranscription(finalTranscript.trim());
          }

        if (interimTranscript) {
          statusText.textContent = `Ouvindo: "${interimTranscript}"`;
        }
      };

      recognition.onerror = (event) => {
        console.error('[v0] Speech recognition error:', event.error);
        if (event.error === 'no-speech') {
          statusText.textContent = 'Nenhuma fala detectada. Tente novamente.';
        } else {
          statusText.textContent = `Erro: ${event.error}`;
        }
      };

      recognition.onend = () => {
        console.log('[v0] Speech recognition ended');
        if (isRecording) {
          // Restart if still in recording mode
          recognition.start();
        } else {
          stopRecording();
        }
      };

      return recognition;
    }

    // Start recording
    function startRecording() {
      if (!recognition) {
        recognition = initSpeechRecognition();
        if (!recognition) return;
      }

      isRecording = true;
      recognition.start();
      micButton.classList.add('bg-red-600', 'hover:bg-red-700');
      micButton.classList.remove('bg-blue-600', 'hover:bg-blue-700');
  // no avatar video playback here; play only when user presses the listen button
    }

    // Stop recording
    function stopRecording() {
      isRecording = false;
      if (recognition) {
        recognition.stop();
      }
      statusText.textContent = 'Aguardando fala...';
      avatarCard.classList.remove('bg-blue-50');
      if (leftArm) leftArm.classList.remove('animate-wave');
      micButton.classList.remove('bg-red-600', 'hover:bg-red-700');
      micButton.classList.add('bg-blue-600', 'hover:bg-blue-700');
    }

    // Add transcription to history
    function addTranscription(text) {
      const timestamp = new Date().toLocaleTimeString('pt-BR', { 
        hour: '2-digit', 
        minute: '2-digit' 
      });

      transcriptions.push({ text, timestamp });

      // Hide welcome message and show transcription list
      welcomeMessage.classList.add('hidden');
      transcriptionList.classList.remove('hidden');

      // Create transcription entry
      const entry = document.createElement('div');
      entry.className = 'bg-white rounded-lg p-4 shadow-sm border border-gray-200';

      const header = document.createElement('div');
      header.className = 'flex justify-between items-start mb-2';

      const timeSpan = document.createElement('span');
      timeSpan.className = 'text-xs text-gray-500';
      timeSpan.textContent = timestamp;

      const playBtn = document.createElement('button');
      playBtn.type = 'button';
      playBtn.className = 'text-blue-600 hover:text-blue-700';
      playBtn.setAttribute('aria-label', 'Ouvir transcri√ß√£o');
      playBtn.innerHTML = `
        <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
        </svg>
      `;

      header.appendChild(timeSpan);
      header.appendChild(playBtn);

      const paragraph = document.createElement('p');
      paragraph.className = 'text-gray-800';
      paragraph.textContent = text;

      entry.appendChild(header);
      entry.appendChild(paragraph);

      // Add click handler: play avatar video first, then speak text
      playBtn.addEventListener('click', () => {
        playAvatarVideo();
        speakText(text, playBtn);
      });

      transcriptionList.insertBefore(entry, transcriptionList.firstChild);
    }

    // Text-to-speech function
    function speakText(text, button) {
      if ('speechSynthesis' in window) {
        // Stop any ongoing speech
        window.speechSynthesis.cancel();

  // do not auto-play avatar video here; playback is triggered by the per-entry listen button

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'pt-BR';
        utterance.rate = 1;
        utterance.pitch = 1;

        // Visual feedback
        button.classList.add('text-green-600');
        if (rightArm) rightArm.classList.add('animate-wave');

        utterance.onend = () => {
          button.classList.remove('text-green-600');
          if (rightArm) rightArm.classList.remove('animate-wave');
        };

        window.speechSynthesis.speak(utterance);
        console.log('[v0] Speaking text:', text);
      } else {
        alert('Seu navegador n√£o suporta s√≠ntese de voz.');
      }
    }

    // Speak last transcription
    function speakLastTranscription() {
      if (transcriptions.length > 0) {
        const lastText = transcriptions[transcriptions.length - 1].text;
  // speak last transcription without triggering avatar video
  speakText(lastText, speakerButton);
      } else {
        alert('Nenhuma transcri√ß√£o dispon√≠vel para reproduzir.');
      }
    }

    // Event listeners
    micButton.addEventListener('click', () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    });

    speakerButton.addEventListener('click', speakLastTranscription);

    // Cleanup on page unload
    window.addEventListener('beforeunload', () => {
      if (recognition) {
        recognition.stop();
      }
      window.speechSynthesis.cancel();
    });
  </script>
</body>
</html>